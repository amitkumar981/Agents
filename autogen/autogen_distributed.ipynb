{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a811de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1ffa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load credentials\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd1d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_IN_AGENTS=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27504a95",
   "metadata": {},
   "source": [
    "### start with master class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9e7fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content:str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274963c",
   "metadata": {},
   "source": [
    "### distributed runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a08e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntimeHost\n",
    "\n",
    "host = GrpcWorkerAgentRuntimeHost(address=\"localhost:8003\")\n",
    "host.start() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b726fd2",
   "metadata": {},
   "source": [
    "### tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8ebcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "serper= GoogleSerperAPIWrapper()\n",
    "lanchain_tool=Tool(name=\"google_search\",func=serper.run,description=\"use when you need to search web\")\n",
    "autogen_tool=LangChainToolAdapter(lanchain_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d44b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction1 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons in favor of choosing AutoGen; the pros of AutoGen.\"\n",
    "\n",
    "instruction2 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons against choosing AutoGen; the cons of Autogen.\"\n",
    "\n",
    "evaluator = \"You must make a decision on whether to use AutoGen for a project. \\\n",
    "Your research team has come up with the following reasons for and against. \\\n",
    "Based purely on the research from your team, please respond with your decision and keep is short.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd99765e",
   "metadata": {},
   "source": [
    "### Build agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0c385ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent1(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model='gpt-4o-mini')\n",
    "        self._delegate = AssistantAgent(\n",
    "            name,\n",
    "            model_client=model_client,\n",
    "            tools=[autogen_tool],\n",
    "            reflect_on_tool_use=True\n",
    "        )\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "\n",
    "\n",
    "class Agent2(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model='gpt-4o-mini')\n",
    "        self._delegate = AssistantAgent(\n",
    "            name,\n",
    "            model_client=model_client,\n",
    "            tools=[autogen_tool],\n",
    "            reflect_on_tool_use=True\n",
    "        )\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "\n",
    "\n",
    "class Evaluator(RoutedAgent):\n",
    "    def __init__(self, name: str):\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model='gpt-4o-mini')\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        # These must be defined elsewhere or passed in\n",
    "        message_1 = Message(content=instruction1)\n",
    "        message_2 = Message(content=instruction2)\n",
    "\n",
    "        inner_1 = AgentId(\"Agent1\", \"default\")\n",
    "        inner_2 = AgentId(\"Agent1\", \"default\")\n",
    "\n",
    "        response1 = await self.send_message(message_1, inner_1)\n",
    "        response2 = await self.send_message(message_2, inner_2)\n",
    "\n",
    "        result = f\"## pros of autogen:\\n{response1.content} \\n\\n## cons of autogen:\\n{response2.content}\"\n",
    "        decision_prompt = f\"{evaluator}\\n{result}\\nRespond with your decision and a brief explanation.\"\n",
    "\n",
    "        decision_message = TextMessage(content=decision_prompt, source=\"user\")\n",
    "        response = await self._delegate.on_messages([decision_message], ctx.cancellation_token)\n",
    "\n",
    "        final_output = result + \"\\n\\n## Decision:\\n\\n\" + response.chat_message.content\n",
    "        return Message(content=final_output)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba649411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntime\n",
    "\n",
    "if ALL_IN_AGENTS:\n",
    "    # Single worker for all agents\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:8003\")\n",
    "    await worker.start()\n",
    "\n",
    "    await Agent1.register(worker, \"player1\", lambda: Agent1(\"Agent1\"))\n",
    "    await Agent2.register(worker, \"player2\", lambda: Agent2(\"Agent2\"))\n",
    "    await Evaluator.register(\n",
    "        worker,\n",
    "        \"judge\",\n",
    "        lambda: Evaluator(\"evaluator\", instruction1, instruction2, evaluator)  \n",
    "    )\n",
    "\n",
    "    agent_id = AgentId(\"evaluator\", \"default\")\n",
    "\n",
    "else:\n",
    "    # Worker for Agent1\n",
    "    worker1 = GrpcWorkerAgentRuntime(host_address=\"localhost:8003\")\n",
    "    await worker1.start()\n",
    "    await Agent1.register(worker1, \"Agent1\", lambda: Agent1(\"Agent1\"))\n",
    "\n",
    "    # Worker for Agent2\n",
    "    worker2 = GrpcWorkerAgentRuntime(host_address=\"localhost:8003\")  \n",
    "    await worker2.start()\n",
    "    await Agent2.register(worker2, \"Agent2\", lambda: Agent2(\"Agent2\"))\n",
    "\n",
    "    # Worker for Evaluator\n",
    "    worker3 = GrpcWorkerAgentRuntime(host_address=\"localhost:8003\")  \n",
    "    await worker3.start()\n",
    "    await Evaluator.register(\n",
    "        worker3,\n",
    "        \"evaluator\",\n",
    "        lambda: Evaluator(\"evaluator\", instruction1, instruction2, evaluator)  \n",
    "    )\n",
    "\n",
    "    agent_id = AgentId(\"evaluator\", \"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await worker3.send_message(Message(content=\"Go!\"), agent_id)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3787d70",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Runtime is not running.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m worker3.stop()\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALL_IN_AGENTS:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m worker1.stop()\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m worker2.stop()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\redhu\\OneDrive\\Desktop\\agents\\.venv\\Lib\\site-packages\\autogen_ext\\runtimes\\grpc\\_worker_runtime.py:311\u001b[39m, in \u001b[36mGrpcWorkerAgentRuntime.stop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Stop the runtime immediately.\"\"\"\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._running:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mRuntime is not running.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    312\u001b[39m \u001b[38;5;28mself\u001b[39m._running = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    313\u001b[39m \u001b[38;5;66;03m# Wait for all background tasks to finish.\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Runtime is not running."
     ]
    }
   ],
   "source": [
    "await worker3.stop()\n",
    "if not ALL_IN_AGENTS:\n",
    "    await worker1.stop()\n",
    "    await worker2.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc09ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
